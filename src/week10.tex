\section{Einstein convention}

Recall \(v\in \mathbb{R}^n\), \(v=(v^1,\ldots,v^n)\implies v=\sum_{i=1}^n v^i e_i\).
\begin{enumerate}[(1)]
    \item The summation is taken over \(i=1,2,\ldots,n\);
    \item \(v=\sum_{i=1}^n v^ie_i=\sum_{j=1}^nv^je_j\), expression of \(v\) is
        independent of choice of summation indices \(i\) or \(j\).
    \item One ``\(i\)'' appears as upper index, another ``\(i\)'' appears as lower
        index.
\end{enumerate}

Einstein convention: Whenever there is pair of same letter as upper and a lower
index, then the expression is summation of the index letter from 1 to \(n\),
\(n\) is usually the dimension of vector space / manifold / etc.

\begin{example}
\begin{itemize}
    \item \(W=V\cdot A\), \(A=(A_i^j)_{n\times n}\) matrix, \(v,w\in \mathbb{R}^n\),
        then \[
            W^j=v^i A_i^j=\sum_{i}v^iA_i^j
        .\] 
    \item \[
        g^{ij}\omega_{jk}=\sum_{j=1}^n g^{ij}\omega_{jk}.
    .\] Where \(g^{ij}\) is the \((i,j)\)-entry of inverse matrix \(g^{-1}\) of
    \(g\). \ie\ \[
        g^{ij}g_{jk}=\delta^i_k,
        \quad g^{ij}g_{ij}=\sum_{i=1}^n \sum_{j=1}^{n}g^{ij}g_{ij}
        =\sum_{i=1}^{n}\delta^i_i=n
    .\] 

    We will use Einstein convention from now on.
\end{itemize}
\end{example}

\section{Therema Egregium (Gauss)}

\underline{Goal:} The Gaussian curvature \(K\) depends only on the 1st fundamental
form.

Previously, we have seen once we know local parametrization \(\vphi(x^1,x^2)\) of
a surface \(S\), then \(I,\II\) can be computed and the Gaussian curvature is \[
    K=\frac{\det \II}{\det I}=\frac{eg-f^2}{EG-F^2}
.\] Now, we want to follow the same procedure as we study the Frenet formula of a
curve and try to understand the motion of equation of frame \(\vphi_1,\vphi_2,N\),
where \(\vphi_i=\pdv{\vphi}{x^i}, N=\frac{\vphi_1\times \vphi_2}{|\vphi_1\times 
\vphi_2|}\).

Fix a local parametrization \[
    \vphi\colon U \longrightarrow S\subset \mathbb{R}^3,
    \ (x^1,x^2)\longmapsto \vphi(x^1,x^2)
.\] Then
\begin{align*}
    I&=g_{ij}\dd{x^i}\dd{x^j},\quad g_{ij}=\left<\vphi_i,\vphi_j\right> \\
    \II&=h_{ij}\dd{x^i}\dd{x^j},\quad h_{ij}
.\end{align*}
We shall study the differential equation of \(\{\vphi_i,N\}\) up to 2nd order.
\begin{align*}
    \vphi_{11}&=\Gamma_{11}^1\vphi_1+\Gamma_{11}^1\vphi_2+h_{11}N\\
    \vphi_{12}&=\Gamma_{12}^1\vphi_1+\Gamma_{12}^1\vphi_2+h_{12}N\\
    \vphi_{21}&=\Gamma_{21}^1\vphi_1+\Gamma_{21}^1\vphi_2+h_{21}N\\
    \vphi_{22}&=\Gamma_{22}^1\vphi_1+\Gamma_{22}^1\vphi_2+h_{22}N\\
.\end{align*}
Weingarten equation, \(A=(a_i^j)\)
\[
    \begin{bmatrix}
        N_1 \\ N_2
    \end{bmatrix}=A\begin{bmatrix}
        \vphi_1 \\ \vphi_2
    \end{bmatrix}
.\] Then \[
    a_i^j=-h_{ik}g^{kj}
.\] Lets write above equations as
\begin{equation}\label{eq:motion}
    \begin{cases}
        \vphi_{ij}=\Gamma_{ij}^k\vphi_k+h_{ij}N \\
        N_i=a_i^j=\vphi_j
    \end{cases}
    \implies \text{The only unknown are }\Gamma_{ij}^k
.\end{equation}
Moreover, \[
    \vphi_{ij}=\vphi_{ji}\implies \Gamma_{ij}^k=\Gamma_{ji}^k
.\] \[
    \left<\vphi_{ij},\vphi_p\right> =\Gamma_{ij}^k \left<\vphi_k,\vphi_p\right> 
    =\Gamma_{ij}^kg_{kl}
.\] So
\begin{gather*}
    \pdv{g_{ip}}{x^j}-\left<\vphi_i,\vphi_{pj}\right> 
    =\left<\vphi_{ij},\vphi_p\right> =\Gamma_{ij}^kg_{kp} \\
    \pdv{g_{jp}}{x^i}-\left<\vphi_j,\vphi_{pi}\right> 
    =\left<\vphi_{ji},\vphi_p\right> =\Gamma_{ji}^kg_{kp} \\
    \pdv{g_{ij}}{x^p}=\left<\vphi_{ip},\vphi_j\right>
    +\left<\vphi_i,\vphi_{jp}\right> 
\end{gather*}
Hence \[
    2\Gamma_{ij}^k g_{kp}=\pdv{g_{jp}}{x^i}+\pdv{g_{ip}}{x^j}-\pdv{g_{ij}}{x_{p}}
.\] \[
    \implies 2\Gamma_{ij}^kg_{kp}g^{pq}
    =(\pdv{g_{jp}}{x^i}+\pdv{g_{ip}}{x^j}-\pdv{g_{ij}}{x_{p}})g^{pq}
.\] We get \[
    \Gamma_{ij}^k=\frac{1}{2}(\pdv{g_{jp}}{x^i}+\pdv{g_{ip}}{x^j}g^{pk}
    -\pdv{g_{ij}}{x_{p}})
.\] 

\begin{remark}
    We multiply \(g^{pk}\) form right because of the choice of row vector. In
    modern convention of the column vector, \[
        \Gamma_{ij}^k=\frac{1}{2}g^{kp}(\pdv{g_{jp}}{x^i}+\pdv{g_{ip}}{x^j}
        -\pdv{g_{ij}}{x_{p}})
    .\] 
\end{remark}
\begin{definition}
    \(\Gamma_{ij}^k\) is called the Christoffel symbols. They're uniquely determined
    by the 1st fundamental form.
\end{definition}

Next we derive the Gauss equation, we'll see the Gaussian curvature can be
expressed only in 1st fundamental form.

So far, we have obtained \[
    \vphi_{ij}=\Gamma_{ij}^k\vphi_k+h_{ij}N
    \quad\&\quad
    N_p=a_p^q\vphi_q
.\] Then
\begin{align*}
    \vphi_{ijp}&= \partial_p \Gamma_{ij}^k\vphi_k+\Gamma_{ij}^k\vphi_{kp}+
    \partial_ph_{ij} N+h_{ij}N_p \\
    &= \partial_p\Gamma_{ij}^k\vphi_k+\Gamma_{ij}^k(\Gamma_{kp}^q+h_{kp}N)
    +\partial_p h_{ij} N+h_{ij}a_p^q \vphi_q, \\
    \vphi_{ipj}
    &= \partial_j\Gamma_{ip}^k\vphi_k+\Gamma_{ip}^k(\Gamma_{kj}^q+h_{kj}N)
    +\partial_j h_{ip} N+h_{ip}a_j^q \vphi_q
.\end{align*}
The derivative is taken in \(\mathbb{R}^3\), so the two expression should be
the same, we got 
\begin{align*}
    \vphi_{ijp}-\vphi_{ipj}
    =&(\partial_p\Gamma_{ij}^k-\partial_j\Gamma_{ip}^k)\vphi_k+(\Gamma_{ij}^k
    \Gamma_{kp}^q-\Gamma_{ip}^k\Gamma_{kj}^q)\vphi_q+(h_{ij}a_p^q-h_{ip}a_j^q)
    \vphi_q &\text{(tangential)} \\
    &+(\Gamma_{ij}^kh_{kp}-\Gamma_{ip}^kh_{kj}+\partial_p h_{ij}-\partial_{j}
    h_{ip})N &\text{(normal)} \\
    =& 0
\end{align*}
\begin{remark}
    If the ambient space is not \(\mathbb{R}^n\), LHS should give curvature of
    the ambient space.
\end{remark}

Note that \(\vphi_i\) and \(N\) are perpendicular, we can split tangential part
and normal part of the equation, and use \(a_{p}^k=-h_{pq}g^{qk}\) we get:

Normal part:
\begin{equation}\label{eq:codazzi}
    \partial_p h_{ij}-\Gamma_{pi}^kh_{kj}=\partial_j h_{ip}-\Gamma_{ji}^kh_{kp}
.\end{equation}

Tangential part: \[
    (h_{ij}h_{pq}-h_{ip}h_{jq})g^{qk}
    =\partial_p \Gamma_{ij}^k-\partial_j\Gamma_{ip}^k
    +\Gamma_{ij}^l\Gamma_{lp}^k-\Gamma_{ip}^l\Gamma_{lj}^k
.\] multiply by \(g^{kr}\) we get
\begin{equation}\label{eq:gauss}
    h_{ij}h_{pq}-h_{ip}h_{jq}=
    g_{qk}\left(\partial_p \Gamma_{ij}^k-\partial_j\Gamma_{ip}^k
    +\Gamma_{ij}^l\Gamma_{lp}^k-\Gamma_{ip}^l\Gamma_{lj}^k\right)
.\end{equation}

\cref{eq:codazzi} is called the Codazzi equation and~\cref{eq:gauss} is called
the Gauss equation. Take \(i=j,p=q\) in Gauss equation, we see LHS becomes \[
    h_{ii}h_{pp}-h_{ip}h_{pi}=\det\begin{bmatrix}
        h_{ii} & h_{ip} \\
        h_{pi} & h_{pp}
    \end{bmatrix}
.\] For 2 dim case, if \(i\neq p\), this gives exactly \(\det\II\). Note RHS
is purely determined by \(I\), hence \(K=\frac{\det\II}{\det I}\) only depends
on \(I\), it is an intrinsic geometric quantity.

{\color{red}\large !} Gaussian curvature is the local geometric invariant of
surfaces.

We look back Codazzi equation, we can add a term as \[
    \partial_{p}h_{ij}-\Gamma_{pi}^kh_{kj}-\boxed{\Gamma_{pj}^kh_{ki}}
    =\partial_{j}h_{ip}-\Gamma_{ji}^kh_{kp}-\boxed{\Gamma_{jp}^kh_{ki}}
.\] In terms of covariant derivative \(\nabla\), this writes \[
    \nabla_p h_{ij}=\nabla_{j} h_{ip}
.\] \ie\ All 3 index of \(\nabla_p h_{ij}\) are symmetric.

\begin{remark}
    We don't need to memorize the Gauss-Codazzi equations precisely. It
    suffices to work it out step by step once we know local parametrization.
    And there is a much more simple form of the equations after we introduced
    notations in Riemannian geometry.
\end{remark}

We also call the Gauss-Codazzi equations are the integrability to solve
the equation of motion~\cref{eq:motion}.

\begin{theorem}[Fundamental theorem of surface theory (local)]\hfill\\
    Let \(U\subset \mathbb{R}^2\) be open, connected set. Given two quadratic
    form \(I=g_{ij}\dd{x^i}\dd{x^j}, \II=h_{ij}\dd{x^i}\dd{x^j}\), \st\ \(I\) is
    positively definite. Moreover, the Gauss-Codazzi equations are satisfied.
    Then there is a surface \(S\) in \(\mathbb{R}^3\) \st\ \(I,\II\) are the 1st
    and 2nd fundamental form of \(S\) with \(U\) a coordinate chart.

    The surface \(S\) is unique up to rigid motion.
\end{theorem}
\begin{proof}
    Skip. (Can be found in Do Carmo's book)
\end{proof}

\section{An invitation of Riemannian Geometry}
We have introduced the concept of smooth manifold \(M\), \ie\ \(M\) is a
topological manifold together with a smooth structure, given by a collection
of coordinate covering \(M=\bigcup_{\alpha}U_\alpha\) \st\ 
\begin{enumerate}[(1)]
    \item \(\vphi_\alpha\colon U_\alpha\to \vphi_\alpha(U_\alpha)\subset
        \mathbb{R}^n\), is homeomorphism.
    \item \(\forall\,\alpha,\beta\), \(U_\alpha\cap U_\beta\neq\emptyset
        \implies\) the transition function \(\vphi_\beta\circ \vphi_\beta^{-1}\)
        on \(U_{\alpha}\cap U_\beta\) is smooth.
\end{enumerate}
Each \((U_\alpha,\vphi_\alpha)\) is called a coordinate patch.

Now a basic question is how to take derivative on \(M\)? This question is
natural to be asked since we want to apply the technique in calculus to study
\(M\).

First, we need to know how to differentiate \(f\in C^\infty(M)\), this has been
done by introducing ``tangent vector'' \& ``tangent vector field''.

Recall a smooth vector field \(X\) on \(M\) is a smooth map sending \(p\in M\)
to a vector \(X_p\in T_pM\). Let \(\Gamma(TM)\) be set of all smooth vector
fields on \(M\). \(X_p\) is understood geometrically as \(\forall\,f\in C^\infty
(M)\), \[
    (Xf)(p)=X_p(f)=\eval{\dv{t}}_{t=0}f(\alpha(t))
    =\lim_{t\to 0}\frac{f(\alpha(t))-f(p)}{t}
.\] Where \(\alpha(t)\) is any curve with initial value \(p\) and initial
velocity \(X_p\). We temporarily take this definition and try to generalize
it to Lie derivative. Soon we shall take the viewpoint that \(X_p\) as first
order derivative and generalize it to covariant derivative.

\subsection{Lie derivative}
Now we want to take derivatives of vector fields. First let's consider \(M=
\mathbb{R}^n\). Let \(V,W\) be two smooth vector fields, \(p\in \mathbb{R}^n\),
and
\begin{equation}\label{eq:lie-diff-Rn}
    \mathrm{D}_{V_p}W(p)=\lim_{t\to 0}\frac{W(p+tV_p)-W(p)}{t}
.\end{equation}
This just means the rate of ``change of value of \(W\)'' w.r.t. the ``change
of points in the domain''.

There're two things to be paid more attention:
\begin{enumerate}[(1)]
    \item \(p+tV_p\in \mathbb{R}^n\) is defined via linear structure of
        \(\mathbb{R}^n\).
    \item \(W(p+tV_p)-W(p)\), again, the subtraction makes sense by the linear
        structure of \(\mathbb{R}^n\). In which, we can identify \[
            T_p \mathbb{R}^n\cong T_{p+tV_p}\mathbb{R}^n\cong \mathbb{R}^n
        .\] 
\end{enumerate}

Next we consider general \(M\) as a manifold, \(V,W\in \Gamma(TM)\). To
generalize~\cref{eq:lie-diff-Rn} to manifolds, we have to reconsider (1) and
(2).
\begin{enumerate}[(1)]
    \item Given \(p\) and initial velocity \(V_p\), we can choose a smooth
    curve \(\alpha(t)\) as a replacement of ``linear perturbation in
    \(\mathbb{R}^n\)''
    \item Then consider the vector field \(W\) (restricted on \(\alpha(t)\)).
    \ie\ \(W(\alpha(t))\in T_{\alpha_(t)}M\). However \(T_{\alpha(t)}\neq
    T_pM\), not the same linear space. To do the subtraction, we need to
    ``move'' \(W(\alpha(t))\) back to \(T_pM\). This can be done by viewing \[
        \alpha(t)\colon p \mapsto \alpha(t)
    \] as a smooth map from \(M\) to \(M\) (at least locally). Then we can
    define a map \[
        \alpha(-t)\colon \alpha_(t) \mapsto p.
        \quad\text{(again from }M\text{ to }M\text{)}
    \] We have
    \begin{align*}
        \dd{\alpha(-t)}_{\alpha(t)}\colon T_{\alpha(t)}M &\longrightarrow
        T_p M \\
        W(\alpha(t)) &\longmapsto \left(\dd{\alpha(-t)}\right)_{\alpha(t)}
        (W(\alpha(t)))\in T_p M
    .\end{align*}
    Then \(\left(\dd{\alpha(-t)}\right)_{\alpha(t)}(W(\alpha(t)))\) and \(W_p\)
    both live in \(T_p M\).
\end{enumerate}

\begin{definition}[Lie derivative] \[
    \mathcal{L}_V W(p):=\lim_{t \to 0} \frac{\left(\dd{\alpha(-t)}_{\alpha(t)}
    \right)(W(\alpha(t)))-W(p)}{t}
\] is called the Lie derivative of \(W\) along \(V\), of course, we can write
above as \[
    \mathcal{L}_V W(p):=\eval{\dv{t}}_{t=0}
    \left(\dd{\alpha(-t)}_{\alpha(t)}\right)(W(\alpha(t)))
.\] 
\end{definition}

Note that \(\mathcal{L}_V W\) is still a smooth vector field (Exercise). The
computational formula is given by
\begin{prop} \[
    \mathcal{L}_V W=\left[V,W\right]=VW-WV
.\] In some books, people just take this as the definition of Lie derivative.
\end{prop}

\([V,W]\) is called the Lie bracket, defined by \(\forall\,f\in C^\infty(M)\),
\[
    [V,W](f)=V(W(f))-W(V(f))
.\] One should check this do give a derivation and defines a smooth vector
field.

Note if we write \(\mathcal{L}_V f=V(f)\), then above equation writes \[
    (\mathcal{L}_V W)(f)=\mathcal{L}_V(W(F))-W(\mathcal{L}_V f)
.\] \ie\ \[
    \mathcal{L}_V(W(f))=(\mathcal{L}_V W)(f)+W(\mathcal{L}_V f)
.\] This is Leibniz rule for Lie derivative.

Locally, let \(V=V^i\pdv{x^i},W=W^j\pdv{x^j}\), then
\begin{align*}
    [V,W]&= [V^i\pdv{x^i},W^j\pdv{x^j}]=V^i\pdv{x^i}(W^j\pdv{x^j})
    -W^j\pdv{x^j}(V^i\pdv{x^i}) \\
    &= V^i\pdv{W^j}{x^i}\pdv{x^j}+V^iW^j\pdv{x^ix^j}
    -W^j\pdv{V^i}{x^j}\pdv{x^i}-W^jV^i\pdv{x^ix^j} \\
    &= V^i\pdv{W^j}{x^i}\pdv{x^j}-W^j\pdv{V^i}{x^j}\pdv{x^i} \\
    &= (V^i\pdv{W^j}{x^i}-W^i\pdv{V^j}{x^i})\pdv{x^j}
.\end{align*}

Let's pause to introducing Lie derivative until we need more properties of it.

\subsection{Affine connection \& Covariant derivative}
Now we take another viewpoint of tangent vector fields. \ie\ A smooth vector
field \(V\) on \(M\) is understood as a 1st order differential operator acting
on \(C^\infty(M)\). \ie\ \(V\in \Gamma(TM)\), \(f\in C^\infty(M)\), \(V(f)\) is
a smooth function \st\ \[
    V(f)(p)=V_p(f)
.\] where \(V_p\colon C^\infty(M)\to \mathbb{R}\) \st\ 
\begin{enumerate}[(1)]
    \item \(V_p(f+\lambda g)=V_p(f+\lambda V_p(g))\),
    \item \(V_p(fg)=V_p(f)g(p)+f(p)V_p(g)\).
\end{enumerate}
Lets also write \(V(f)=\nabla_V f\), then \(\forall\,V,W\in \Gamma(TM)\),
\(h\in C^\infty(M)\), we have \[
    \nabla\colon \Gamma(TM)\times C^\infty(M)\to C^\infty(M),
    \quad(V,f)\mapsto \nabla_V f,
\]
satisfies:
\begin{enumerate}[(1)]
    \item \(\nabla_{V+hW}f=\nabla_V f+h\nabla_W f\),
    \item \(\nabla_V(f+\lambda h)=\nabla_V f+\lambda \nabla_V h\),
    \item \(\nabla_V(fh)=(\nabla_V)h+f\nabla_V h\).
\end{enumerate}

In a similar fashion, we define the covariant derivative \(\nabla_V W\),
by requiring (1)-(3) above, more precisely, \(\forall\,V,W,Z\in \Gamma(TM),
f\in C^\infty(M),\lambda\in \mathbb{R}\),
\begin{enumerate}[(1)]
    \item \(\nabla_{V+fZ}W=\nabla_V w+f\nabla_Z W\). (\(C^\infty\)-linear
        in subscript vector filed)
    \item \(\nabla_V(W+\lambda Z)=\nabla_V W+\lambda\nabla_V Z\).
        (\(\mathbb{R}\)-linear in vector fields)
    \item \(\nabla_V(fW)=(\nabla_V f)W+f\nabla_V W\). (Leibniz rule)
\end{enumerate}
